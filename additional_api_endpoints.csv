Category,Endpoint,Method,Called From,When It's Called,Request / Params,Main Response / Purpose
Training,/train/base-models?company={name}&project={name},GET,SimulationView.tsx (fetchBaseModels),On model type selection == YOLO or when project changes,Query: company (optional) project (optional),"Returns available base YOLO models: { baseModels: [{ size, label, sizeMB, ... }], trainedModels: [...] }"
Training,/train/defaults?modelType={type},GET,SimulationView.tsx (fetchDefaultParams),On model type change to load default hyperparameters,Query: modelType (YOLO EfficientNet Custom),"Returns default training hyperparameters: { epochs, batchSize, imgSize, learningRate, workers, ... }"
Training,/datasets?status=ready&projectId={id}&project={name},GET,SimulationView.tsx (fetchDatasets),When a project is selected and session is ready,Query: status=ready projectId (optional) project (optional),"Returns list of ready datasets for the chosen project (filtered by status=ready)"
Training,/models?projectId={id}&company={name}&project={name},GET,SimulationView.tsx (fetchTrainedModels),When project is selected or changes,Query: projectId (optional) company (optional) project (optional),"Returns array of trained models: { models: [{ modelId, modelVersion, modelType, status, ... }] }"
Models,model.downloadUrl (e.g. /api/models/{modelId}/download),GET,SimulationView.tsx (Model Information section),When displaying model info after training completes; user clicks download link,Path: modelId (embedded in URL from model object),Returns/downloads the trained model file (weight file). URL is provided in model metadata from training status/response
Inference,/inference/datasets?company={name}&project={name},GET,PredictionPage.tsx (fetchDatasets),When project is selected and session is ready,Query: company project,"Returns list of datasets available for inference/prediction for the selected project"
Inference,/inference/models?company={name}&project={name},GET,PredictionPage.tsx (fetchModels),When project is selected and session is ready,Query: company project,"Returns list of trained models available for inference: { models: [{ modelId, modelVersion, modelType, ... }] }"
Inference,/inference?company={name}&project={name}&status={status},GET,PredictionPage.tsx (fetchPastInferences),When in history view mode and project is selected,Query: company project status (optional filter: 'all' 'completed' 'failed' etc.),"Returns array of past inference jobs: { inferenceJobs: [{ inferenceId, status, model, dataset, startedAt, completedAt, ... }] }"
Inference,/inference/{inferenceId}/results,GET,"PredictionPage.tsx (fetchResults) and PredictionHistoryDetailsPage.tsx",When viewing results for current inference or when loading history details page,Path: inferenceId,"Returns inference results: { results: { annotatedImages: [{ url, detections, ... }], detectionsByClass: [...], totalDetections, ... } }"
Inference,/inference/{inferenceId}/status,GET,PredictionPage.tsx (checkInferenceStatus),Every 2-3 seconds while inference is active (polling) once on page reload,Path: inferenceId,Returns inference status: { status, progress, processedImages, totalImages, ... }
Inference,/inference/{inferenceId}/cancel,POST,PredictionPage.tsx (cancelInference),When user clicks 'Cancel' during queued/running state,Path: inferenceId,Requests inference job cancellation; returns new status. Error 400 if cannot cancel.
Inference,/inference/{inferenceId},DELETE,PredictionPage.tsx (deleteInference),When user confirms deletion of inference results,Path: inferenceId,"Permanently deletes inference job and results. Error 400 if job is running/queued."


